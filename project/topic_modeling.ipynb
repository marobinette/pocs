{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "import nltk\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Great resource for topic modeling which I followed to create this script\n",
    "# https://towardsdatascience.com/6-tips-to-optimize-an-nlp-topic-model-for-interpretability-20742f3047e2?gi=9d97408c65b1\n",
    "stop_word_list = set(stopwords.words('english'))\n",
    "\n",
    "response = requests.get(url)\n",
    "data = response.text.strip().splitlines()\n",
    "comedy_data = [json.loads(line) for line in data]\n",
    "df = pd.DataFrame(comedy_data, columns=['title', 'transcript'])\n",
    "mitch = df['transcript'][0]\n",
    "\n",
    "documents = mitch  # mitch hedberg's comedy special\n",
    "\n",
    "bigram_measures = BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_documents([doc.split() for doc in documents])\n",
    "finder.apply_freq_filter(2)\n",
    "\n",
    "# Function to filter bigrams based on noun structures\n",
    "def bigram_filter(bigram):\n",
    "    tag = pos_tag(bigram)\n",
    "    if tag[0][1] in ['JJ', 'NN'] and tag[1][1] in ['NN']:\n",
    "        return bigram[0] not in stop_word_list and bigram[1] not in stop_word_list\n",
    "    return False\n",
    "\n",
    "# Score bigrams and filter by PMI and noun structure\n",
    "filtered_bigrams = [(bigram, score) for bigram, score in finder.score_ngrams(bigram_measures.pmi)\n",
    "                    if bigram_filter(bigram) and score > 5]\n",
    "\n",
    "# Prepare bigram phrases for replacement\n",
    "bigrams = [' '.join(bigram) for bigram, score in filtered_bigrams]\n",
    "\n",
    "# Function to replace bigrams and filter nouns\n",
    "def replace_and_filter_ngrams(text):\n",
    "    for gram in bigrams:\n",
    "        text = text.replace(gram, '_'.join(gram.split()))\n",
    "    tokens = [word for word in text.split() if word not in stop_word_list and len(word) > 2]\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    filtered = [word for word, pos in pos_tags if pos.startswith('NN')]\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "# Apply to documents\n",
    "filtered_documents = [replace_and_filter_ngrams(doc) for doc in documents if len(doc.strip()) > 0]\n",
    "\n",
    "# Create dictionary and corpus for Gensim\n",
    "vectorizer = CountVectorizer(stop_words='english', min_df=2)\n",
    "doc_term_matrix = vectorizer.fit_transform(filtered_documents)\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "dictionary = corpora.Dictionary([terms])\n",
    "corpus = [dictionary.doc2bow(doc.split()) for doc in filtered_documents]\n",
    "\n",
    "# Calculate coherence for a range of topics\n",
    "# tune chunksize and passes for better performance\n",
    "coherence = []\n",
    "for k in range(1, 9):\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(\n",
    "        corpus=corpus, num_topics=k, id2word=dictionary, passes=40, iterations=200,\n",
    "        chunksize=4000, eval_every=None\n",
    "    )\n",
    "    \n",
    "    # Use 'c_v' coherence for interpretability\n",
    "    coherence_model = CoherenceModel(model=lda_model, texts=[doc.split() for doc in filtered_documents], \n",
    "                                     dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    coherence.append((k, coherence_score))\n",
    "\n",
    "# Output coherence scores\n",
    "# print(\"\\nCoherence Scores by Number of Topics:\")\n",
    "for num_topics, score in coherence:\n",
    "    print(f\"{num_topics} topics: Coherence score = {score}\")\n",
    "vis = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.display(vis)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
