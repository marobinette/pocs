{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/robinwoodfamily/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/robinwoodfamily/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/robinwoodfamily/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['answers, they’ll', 'drug use.', 'roast beef.', 'standup comedian.', 'use liquor', 'death metal', 'emergency brake.', 'him.” “And', 'on, man.', 'gonna redo', 'right. You’re', 'think that’s', 'don’t know.', 'didn’t get', '“I don’t', 'can’t get']\n",
      "1 topics: Coherence score = 0.29581227450939973\n",
      "2 topics: Coherence score = 0.30874377104061446\n",
      "3 topics: Coherence score = 0.4041151018496619\n",
      "4 topics: Coherence score = 0.415306893211147\n",
      "5 topics: Coherence score = 0.5312187843974392\n",
      "6 topics: Coherence score = 0.5501523252688106\n",
      "7 topics: Coherence score = 0.4503830131641474\n",
      "8 topics: Coherence score = nan\n",
      "LdaModel<num_terms=545, num_topics=8, decay=0.5, chunksize=4000>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/gensim/topic_coherence/direct_confirmation_measure.py:204: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  m_lr_i = np.log(numerator / denominator)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/gensim/topic_coherence/indirect_confirmation_measure.py:323: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return cv1.T.dot(cv2)[0, 0] / (_magnitude(cv1) * _magnitude(cv2))\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import csv\n",
    "\n",
    "# NLTK downloads\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_word_list = set(stopwords.words('english'))\n",
    "\n",
    "# Load the data and select a single transcript\n",
    "response = requests.get(url)\n",
    "data = response.text.strip().splitlines()\n",
    "comedy_data = [json.loads(line) for line in data]\n",
    "df = pd.DataFrame(comedy_data, columns=['title', 'transcript'])\n",
    "\n",
    "# Use only the first transcript (or specify by index)\n",
    "transcript = df['transcript'][0]\n",
    "\n",
    "# If transcript is a list, join it into a single string\n",
    "if isinstance(transcript, list):\n",
    "    transcript = \" \".join(transcript)\n",
    "\n",
    "# Split the transcript by '\\n' to create separate documents for each joke or line\n",
    "documents = transcript.split('\\n')\n",
    "documents = [joke.strip() for joke in documents if joke.strip()]\n",
    "\n",
    "# Simplified tokenization, filtering, and POS tagging\n",
    "def preprocess_text(text):\n",
    "    # Tokenize and remove stop words\n",
    "    tokens = [word for word in text.split() if word not in stop_word_list and len(word) > 2]\n",
    "    # Keep only nouns\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    filtered = [word for word, pos in pos_tags if pos.startswith('NN')]\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "# Apply to documents and filter out any empty strings\n",
    "filtered_documents = [preprocess_text(doc) for doc in documents if len(doc.strip()) > 0]\n",
    "\n",
    "# Tokenize and remove stop words early\n",
    "def tokenize_and_filter(doc):\n",
    "    tokens = [word for word in doc.split() if len(word) > 2]\n",
    "    return tokens\n",
    "\n",
    "tokenized_docs = [tokenize_and_filter(doc) for doc in filtered_documents]\n",
    "\n",
    "# Create dictionary and filter extremes\n",
    "dictionary = corpora.Dictionary(tokenized_docs)\n",
    "dictionary.filter_extremes(no_below=1, no_above=0.8)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
    "\n",
    "# Remove any empty documents from corpus and tokenized_docs\n",
    "corpus = [doc for doc in corpus if len(doc) > 0]\n",
    "tokenized_docs = [doc for doc in tokenized_docs if len(doc) > 0]\n",
    "\n",
    "# Calculate coherence for a range of topics and store the best model\n",
    "best_coherence_score = -1  # Initialize with a low value\n",
    "best_k = None  # Store the best number of topics\n",
    "best_lda_model = None  # Store the best LDA model\n",
    "\n",
    "for k in range(23, 58):  # Adjust the range for fewer topics if needed\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(\n",
    "        corpus=corpus, num_topics=k, id2word=dictionary, passes=80, iterations=240,\n",
    "        chunksize=70, eval_every=None\n",
    "    )\n",
    "\n",
    "    coherence_model = CoherenceModel(model=lda_model, texts=tokenized_docs, \n",
    "                                     dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    print(f\"{k} topics: Coherence score = {coherence_score}\")\n",
    "    \n",
    "    # Update the best model if this coherence score is higher\n",
    "    if coherence_score > best_coherence_score:\n",
    "        best_coherence_score = coherence_score\n",
    "        best_k = k\n",
    "        best_lda_model = lda_model\n",
    "\n",
    "# Print the model with the highest coherence score\n",
    "print(f\"\\nBest model with {best_k} topics has the highest coherence score: {best_coherence_score}\")\n",
    "\n",
    "# Map each joke to its dominant topic and the top word/phrase from that topic\n",
    "joke_topic_mapping = []\n",
    "for i, bow in enumerate(corpus):\n",
    "    topic_distribution = best_lda_model.get_document_topics(bow)\n",
    "    # Find the dominant topic with the highest probability\n",
    "    dominant_topic = max(topic_distribution, key=lambda x: x[1])[0]\n",
    "    \n",
    "    # Get the top word/phrase for the dominant topic\n",
    "    top_words_for_topic = best_lda_model.show_topic(dominant_topic, topn=1)\n",
    "    dominant_word_or_phrase = top_words_for_topic[0][0]  # The top word/phrase\n",
    "    \n",
    "    joke_topic_mapping.append({\n",
    "        \"Joke\": documents[i], \n",
    "        \"Dominant Topic\": dominant_topic,\n",
    "        \"Top Word/Phrase\": dominant_word_or_phrase\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and write to CSV\n",
    "joke_topic_df = pd.DataFrame(joke_topic_mapping)\n",
    "joke_topic_df.to_csv('jokes_to_topics_and_words.csv', index=False)\n",
    "\n",
    "print(\"\\nJokes mapped to topics and top words/phrases written to 'jokes_to_topics_and_words.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
